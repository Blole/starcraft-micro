\section{Introduction amd Background}
RTS games provide a very interesting platform for developing and testing multi agent coordination.
%In game theoretic terms, RTS games can be considered symmetric, non-zero-sum, simultaneous, imperfect information, combinatorial games.
That which separates RTS games the most from traditional games like chess is the huge branching factor when taking every possible combination of every unit's allowed moves into account, and even in a 10 vs 10 unit battle, all the different ways a battle could play out quickly grows beyond what is feasible to perform an exhaustive search on.
On top of that, a complete model of how the game mechanics work might not be available, and new decisions have to be taken in only the time between each frame
\footnote{
As an example, in the 2011 AIIDE \textsc{Starcraft} AI Competition, 55 ms were given to the bots per frame.
\url{https://skatgame.net/mburo/sc2011/rules.html}
}
.

The game of \textsc{Starcraft} is a good platform for evaluating different methods for addressing these difficulties and several tournaments are held yearly
\footnote{
\url{http://www.sscaitournament.com/}\\ 
\url{http://www.aiide.org/starcraft} \\
\url{http://bots-stats.krasi0.com/} (ladder)
}
.

The game can be roughly divided into two parts, managing the economy (to produce combat units), and managing combat units.
The term \emph{micromanagement} can be used to describe the low-level actions performed by the player in both the economic and the combat aspects of the game, but we will henceforth only refer to it in the context of combat.
For micromanagement, most of current bots such as \emph{UAlbertaBot} and \emph{Skynet}, the two top winning bots in the 2013 AIIDE \textsc{Starcraft} AI competition,
\footnote{\url{http://webdocs.cs.ualberta.ca/~cdavid/starcraftaicomp/report2013.shtml}
}
use scripted behaviors.
Scripted behaviors are usually relatively simple preprogrammed descriptions of what course of action should be taken for a given state of the world, for example, attack the closest enemy.
These algorithms provide good results in term of computational speed but often lack in foresight.
Another approach is to use search-based methods, which naturally adapt to the current situtation.
Looking ahead often allows for finding winning variations where scripted solutions fail because they cannot be preprogrammed to handle every possible state that is in theory winnable.
For reference, in the games of Chess or Go, the problem of finding an optimal winning solution has been proven to be NP-HARD \cite{nphard}.

%\section{Related Work}
%...

However even classical search based method have to be modified in order to take in account simultaneous and non-instaneous moves of RTS games.
In \cite{abcd} a fast search method -- Alpha-Beta search for duratives moves -- is presented and proven better than commonly used AI scripts (with battle up to 8 vs 8 units). 
\cite{wargusuct} investigates the use of UCT -- a Monte-Carlo planning algorithm for this problem -- and provide a battle planning strategy better than several baselines and even a human player.
