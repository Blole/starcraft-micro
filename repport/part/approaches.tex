\section{Approaches to micromanagement}
There are atleast two different groups of algorithms for solving micromanagement can be divided into: scripted and searching.
In scripted behaviors the action to be taken for a given state is determined by some predefined rules, and for example encoded in a finite-state machine or behavior tree.
This is perhaps the most widely used technique today, the built-in AI of \textsc{Starcraft} seems to use some variant of it.
Searching algorithms on the other hand work by simulating the game into the future, trying out different move combinations and counter move combinations as far into the future as there is time to simulate, and choosing the most promising course of action.

\subsection{Scripted behaviors}
The three scripted behaviors we have implemented are
\begin{shortitem}
\item \texttt{Attack Closest:}					Every unit attacks their closest enemy.
\item \texttt{Attack Closest -- No Overkill:}	Every unit attacks their closest enemy that is not already attributed enough damage to kill it soon.
\item \texttt{Kiting:}							Every unit attacks their closest enemy while applying a kiting strategy, more on this later.
\end{shortitem}

Note that out of these, only in the \texttt{Attack Closest -- No Overkill} do the units share any information with each other, namely which target they attack next; in the other two scripts every unit acts on its own.

\subsection {Searching algorithms}
The two searching algorithms we have implemented are
\begin{shortitem}
\item \texttt{UCT-Searching:}	UCT, Upper Confidence Bound for Trees, the most popular Monte-Carlo Tree Search algorithm. \cite{mcts}
\item \texttt{ABCD-Searching:}	ABCD, Alpha-Beta Considering Durations, a searching algorithm based on the alpha-beta algorithm adapted to durative moves in \cite{abcd}.
\end{shortitem}
In these algorithms, the units not only share information but are rather considered as a single entity, like the fingers of a hand, and are coordinated.
More on these later.
